{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Aggregating-Functions\" data-toc-modified-id=\"Aggregating-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Aggregating Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-Simple-Aggregations\" data-toc-modified-id=\"Example-Simple-Aggregations-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Example Simple Aggregations</a></span></li></ul></li><li><span><a href=\"#Grouping-in-SQL\" data-toc-modified-id=\"Grouping-in-SQL-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Grouping in SQL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-GROUP-BY--Statements\" data-toc-modified-id=\"Example-GROUP-BY--Statements-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Example <code>GROUP BY</code>  Statements</a></span><ul class=\"toc-item\"><li><span><a href=\"#Without-GROUP-BY\" data-toc-modified-id=\"Without-GROUP-BY-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Without <code>GROUP BY</code></a></span></li><li><span><a href=\"#With-GROUP-BY\" data-toc-modified-id=\"With-GROUP-BY-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>With <code>GROUP BY</code></a></span></li></ul></li><li><span><a href=\"#Group-Task\" data-toc-modified-id=\"Group-Task-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Group Task</a></span></li><li><span><a href=\"#Exercise:-Grouping\" data-toc-modified-id=\"Exercise:-Grouping-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Exercise: Grouping</a></span></li></ul></li><li><span><a href=\"#Filtering-Groups-with-HAVING\" data-toc-modified-id=\"Filtering-Groups-with-HAVING-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Filtering Groups with <code>HAVING</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-Using-HAVING\" data-toc-modified-id=\"Examples-of-Using-HAVING-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Examples of Using <code>HAVING</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-Filtering---Number-of-Airports-in-a-Country\" data-toc-modified-id=\"Simple-Filtering---Number-of-Airports-in-a-Country-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Simple Filtering - Number of Airports in a Country</a></span></li></ul></li><li><span><a href=\"#Filtering-Different-Aggregations---Airport-Altitudes\" data-toc-modified-id=\"Filtering-Different-Aggregations---Airport-Altitudes-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Filtering Different Aggregations - Airport Altitudes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Looking-at-the-airports-Table\" data-toc-modified-id=\"Looking-at-the-airports-Table-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Looking at the <code>airports</code> Table</a></span></li><li><span><a href=\"#Looking-at-the-Highest-Airport\" data-toc-modified-id=\"Looking-at-the-Highest-Airport-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Looking at the Highest Airport</a></span></li><li><span><a href=\"#Looking-at-the-Number-of-Airports-Too\" data-toc-modified-id=\"Looking-at-the-Number-of-Airports-Too-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Looking at the Number of Airports Too</a></span></li><li><span><a href=\"#Filtering-on-Aggregations\" data-toc-modified-id=\"Filtering-on-Aggregations-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Filtering on Aggregations</a></span></li></ul></li></ul></li><li><span><a href=\"#Joins\" data-toc-modified-id=\"Joins-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Joins</a></span><ul class=\"toc-item\"><li><span><a href=\"#INNER-JOIN\" data-toc-modified-id=\"INNER-JOIN-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><code>INNER JOIN</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Example-for-Inner-Joins\" data-toc-modified-id=\"Code-Example-for-Inner-Joins-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Code Example for Inner Joins</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inner-Join-Routes-&amp;-Airline-Data\" data-toc-modified-id=\"Inner-Join-Routes-&amp;-Airline-Data-5.1.1.1\"><span class=\"toc-item-num\">5.1.1.1&nbsp;&nbsp;</span>Inner Join Routes &amp; Airline Data</a></span></li><li><span><a href=\"#Note:-Losing-Data-with-Inner-Joins\" data-toc-modified-id=\"Note:-Losing-Data-with-Inner-Joins-5.1.1.2\"><span class=\"toc-item-num\">5.1.1.2&nbsp;&nbsp;</span>Note: Losing Data with Inner Joins</a></span></li></ul></li></ul></li><li><span><a href=\"#LEFT-JOIN\" data-toc-modified-id=\"LEFT-JOIN-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span><code>LEFT JOIN</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-Example-for-Left-Join\" data-toc-modified-id=\"Code-Example-for-Left-Join-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Code Example for Left Join</a></span></li></ul></li><li><span><a href=\"#Exercise:-Joins\" data-toc-modified-id=\"Exercise:-Joins-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Exercise: Joins</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Execution-Order\" data-toc-modified-id=\"Level-Up:-Execution-Order-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up: Execution Order</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sql](images/sql-logo.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasql in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from pandasql) (1.21.5)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from pandasql) (1.4.32)\n",
      "Requirement already satisfied: pandas in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from pandasql) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from pandas->pandasql) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alvaro\\anaconda3\\lib\\site-packages (from sqlalchemy->pandasql) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pandasql\n",
    "\n",
    "conn = sqlite3.connect(\"./data/flights.db\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use SQL aggregation functions with GROUP BY\n",
    "- Use HAVING for group filtering\n",
    "- Use SQL JOIN to combine tables using keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Aggregating Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">  A SQL **aggregating function** takes in many values and returns one value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have already seen some SQL aggregating functions like `COUNT()`. There are also others, like SUM(), AVG(), MIN(), and MAX()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example Simple Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAX(CAST(longitude AS REAL))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179.951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAX(CAST(longitude AS REAL))\n",
       "0                       179.951"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max value for longitude\n",
    "pd.read_sql('''\n",
    "    SELECT \n",
    "        -- Note we have to cast to a numerical value first\n",
    "        \n",
    "        MAX(CAST(longitude AS REAL))\n",
    "        \n",
    "    FROM \n",
    "        airports\n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Effectively counts all the inactive airlines \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Grouping in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can go deeper and use aggregation functions on _groups_ using the `GROUP BY` clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `GROUP BY` clause will group one or more columns together with the same values as one group to perform aggregation functions on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example `GROUP BY`  Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's say we want to know how many active and non-active airlines there are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Without `GROUP BY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's first start with just seeing how many airlines there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Count Airlines\n",
    "df_results = pd.read_sql('''\n",
    "    SELECT \n",
    "        -- Reminder that this counts the number of rows before the SELECT\n",
    "        COUNT() AS number_of_airlines\n",
    "    FROM \n",
    "        airlines\n",
    "''', conn)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One way for us to get the counts for each is to create two queries that will filter each kind of airline (active vs non-active) and count those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_active = pd.read_sql('''\n",
    "    SELECT \n",
    "        COUNT() AS number_of_active_airlines\n",
    "    FROM \n",
    "        airlines\n",
    "    WHERE \n",
    "        active='Y'\n",
    "''', conn)\n",
    "\n",
    "df_not_active = pd.read_sql('''\n",
    "    SELECT \n",
    "        COUNT() AS number_of_not_active_airlines\n",
    "    FROM \n",
    "        airlines\n",
    "    WHERE \n",
    "        active='N'\n",
    "''', conn)\n",
    "\n",
    "display(df_active)\n",
    "display(df_not_active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This works but it's inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### With `GROUP BY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead, we can tell the SQL server to do the work for us by grouping values we care about for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group By\n",
    "pd.read_sql('''\n",
    "    SELECT\n",
    "        -- Note we have to cast to numerical value first\n",
    "        \n",
    "        MAX(CAST(longitude AS REAL))\n",
    "    FROM\n",
    "        airports\n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is great! And if you look closely, you can observe we have _three_ different groups instead of our expected two!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's also print out the `airlines.active` value for each group/aggregation so we know what we're looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# What're the groups again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Group Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Which countries have the highest numbers of active airlines? Return the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "df_airlines = pd.read_sql('''\n",
    "SELECT\n",
    "    country,\n",
    "    COUNT(*) AS num_active\n",
    "FROM\n",
    "    airlines\n",
    "WHERE\n",
    "    active = 'Y'\n",
    "GROUP BY\n",
    "    country\n",
    "ORDER BY \n",
    "    \"num_active\" DESC\n",
    "LIMIT 10\n",
    "    \n",
    "''', conn)\n",
    "\n",
    "display(df_airlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note that the `GROUP BY` clause is considered _before_ the `ORDER BY` and `LIMIT` clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise: Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Run a query that will return the number of airports by time zone. Each row should have a number of airports and a time zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Filtering Groups with `HAVING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We showed that you can filter tables with `WHERE`. We can similarly filter _groups/aggregations_ using `HAVING` clauses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Examples of Using `HAVING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simple Filtering - Number of Airports in a Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's come back to the aggregation of active airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql('''\n",
    "    SELECT \n",
    "        COUNT() AS num,\n",
    "        country\n",
    "    FROM \n",
    "        airlines\n",
    "    WHERE \n",
    "        active='Y'\n",
    "    GROUP BY \n",
    "        country\n",
    "    ORDER BY \n",
    "        num DESC\n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see we have a lot of results. But maybe we only want to keep the countries that have more than $30$ active airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Having"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Filtering Different Aggregations - Airport Altitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also filter on other aggregations. For example, let's say we want to investigate the `airports` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Specifically, we want to know the height of the _highest airport_ in a country given that it has _at least $100$ airports_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Looking at the `airports` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Airports!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Looking at the Highest Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's first get the highest altitude airport for each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Looking at the Number of Airports Too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also get the number of airports for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n\nselect\n    name,\n    country,\n    MAX(CAST(altitude as REAL)),\n    MIN(CAST)\nfrom\n    airports\ngroup by\n    country\n\n': near \")\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \")\": syntax error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# How many in each country\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m highest_ap_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43mselect\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43m    name,\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m    country,\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m    MAX(CAST(altitude as REAL)),\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m    MIN(CAST)\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43mfrom\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43m    airports\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43mgroup by\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43m    country\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m highest_ap_df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    563\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2070\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2077\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2080\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2081\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\n\nselect\n    name,\n    country,\n    MAX(CAST(altitude as REAL)),\n    MIN(CAST)\nfrom\n    airports\ngroup by\n    country\n\n': near \")\": syntax error"
     ]
    }
   ],
   "source": [
    "# How many in each country\n",
    "highest_ap_df = pd.read_sql('''\n",
    "\n",
    "select\n",
    "    name,\n",
    "    country,\n",
    "    MAX(CAST(altitude as REAL)),\n",
    "    MIN(CAST)\n",
    "from\n",
    "    airports\n",
    "group by\n",
    "    country\n",
    "\n",
    "''', conn)\n",
    "highest_ap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Filtering on Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Recall:\n",
    ">\n",
    "> We want to know the height of the _highest airport_ in a country given that it has _at least $100$ airports_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# having"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The biggest advantage in using a relational database (like we've been with SQL) is that you can create **joins**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> By using **`JOIN`** in our query, we can connect different tables using their _relationships_ to other tables.\n",
    ">\n",
    "> Usually we use a key (*foreign key*) to tell us how the two tables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are different types of joins and each has their different use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `INNER JOIN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> An **inner join** will join two tables together and only keep rows if the _key is in both tables_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](./images/inner_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example of an inner join:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    table1.column_name,\n",
    "    table2.different_column_name\n",
    "FROM\n",
    "    table1\n",
    "    INNER JOIN table2\n",
    "        ON table1.shared_column_name = table2.shared_column_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code Example for Inner Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's say we want to look at the different airplane routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_id</th>\n",
       "      <th>source</th>\n",
       "      <th>source_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_id</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>stops</th>\n",
       "      <th>equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>AER</td>\n",
       "      <td>2965</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>MRV</td>\n",
       "      <td>2962</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>OVB</td>\n",
       "      <td>4078</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67658</th>\n",
       "      <td>67658</td>\n",
       "      <td>ZL</td>\n",
       "      <td>4178</td>\n",
       "      <td>WYA</td>\n",
       "      <td>6334</td>\n",
       "      <td>ADL</td>\n",
       "      <td>3341</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>SF3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67659</th>\n",
       "      <td>67659</td>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>DME</td>\n",
       "      <td>4029</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>67660</td>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>DME</td>\n",
       "      <td>4029</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67661</th>\n",
       "      <td>67661</td>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>OSS</td>\n",
       "      <td>2913</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67662</th>\n",
       "      <td>67662</td>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>OSS</td>\n",
       "      <td>2913</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67663 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index airline airline_id source source_id dest dest_id codeshare stops  \\\n",
       "0          0      2B        410    AER      2965  KZN    2990      None     0   \n",
       "1          1      2B        410    ASF      2966  KZN    2990      None     0   \n",
       "2          2      2B        410    ASF      2966  MRV    2962      None     0   \n",
       "3          3      2B        410    CEK      2968  KZN    2990      None     0   \n",
       "4          4      2B        410    CEK      2968  OVB    4078      None     0   \n",
       "...      ...     ...        ...    ...       ...  ...     ...       ...   ...   \n",
       "67658  67658      ZL       4178    WYA      6334  ADL    3341      None     0   \n",
       "67659  67659      ZM      19016    DME      4029  FRU    2912      None     0   \n",
       "67660  67660      ZM      19016    FRU      2912  DME    4029      None     0   \n",
       "67661  67661      ZM      19016    FRU      2912  OSS    2913      None     0   \n",
       "67662  67662      ZM      19016    OSS      2913  FRU    2912      None     0   \n",
       "\n",
       "      equipment  \n",
       "0           CR2  \n",
       "1           CR2  \n",
       "2           CR2  \n",
       "3           CR2  \n",
       "4           CR2  \n",
       "...         ...  \n",
       "67658       SF3  \n",
       "67659       734  \n",
       "67660       734  \n",
       "67661       734  \n",
       "67662       734  \n",
       "\n",
       "[67663 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "    \n",
    "        routes \n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is great but notice the `airline_id` column. It'd be nice to have some more information about the airlines associated with these routes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can do an **inner join** to get this information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Inner Join Routes & Airline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df = pd.read_sql('''SELECT * from AIRLINES''', conn)\n",
    "airlines_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT\n    rt.source AS departing,\n    re.dest AS arriving,\n    al.name,\n    rt.airline_id AS routes_id,\n    al.id as airline_id\nFROM\n    routes AS rt\n    INNER JOIN airlines AS al\n        ON rt.airline_id = al.id\n        \n': no such column: re.dest",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such column: re.dest",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inner\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m airlines_ID \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43mSELECT\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43m    rt.source AS departing,\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43m    re.dest AS arriving,\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m    al.name,\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m    rt.airline_id AS routes_id,\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m    al.id as airline_id\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43mFROM\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43m    routes AS rt\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43m    INNER JOIN airlines AS al\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43m        ON rt.airline_id = al.id\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    563\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2070\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2077\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2080\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2081\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT\n    rt.source AS departing,\n    re.dest AS arriving,\n    al.name,\n    rt.airline_id AS routes_id,\n    al.id as airline_id\nFROM\n    routes AS rt\n    INNER JOIN airlines AS al\n        ON rt.airline_id = al.id\n        \n': no such column: re.dest"
     ]
    }
   ],
   "source": [
    "# Inner\n",
    "airlines_ID = pd.read_sql('''\n",
    "SELECT\n",
    "    rt.source AS departing,\n",
    "    re.dest AS arriving,\n",
    "    al.name,\n",
    "    rt.airline_id AS routes_id,\n",
    "    al.id as airline_id\n",
    "FROM\n",
    "    routes AS rt\n",
    "    INNER JOIN airlines AS al\n",
    "        ON rt.airline_id = al.id\n",
    "        \n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df = pd.read_sql('''SELECT * from AIRLINES''', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also specify that we want to retain only certain columns in the `SELECT` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inner and Select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Note: Losing Data with Inner Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since data rows are kept only if _both_ tables have the key, some data can be lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n    SELECT \n        *\n    FROM\n        routes\n        INNER JOIN airlines\n            ON routes.airline_id = al.id\n': no such column: al.id",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such column: al.id",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df_all_routes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m        *\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    FROM\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m        routes\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m'''\u001b[39m, conn)\n\u001b[1;32m----> 8\u001b[0m df_routes_after_join \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43m    SELECT \u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43m        *\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43m    FROM\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43m        routes\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;43m        INNER JOIN airlines\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;43m            ON routes.airline_id = al.id\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    563\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2070\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2077\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2080\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2081\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\n    SELECT \n        *\n    FROM\n        routes\n        INNER JOIN airlines\n            ON routes.airline_id = al.id\n': no such column: al.id"
     ]
    }
   ],
   "source": [
    "df_all_routes = pd.read_sql('''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        routes\n",
    "''', conn)\n",
    "\n",
    "df_routes_after_join = pd.read_sql('''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        routes\n",
    "        INNER JOIN airlines\n",
    "            ON routes.airline_id = airlines.id\n",
    "''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at how the number of rows are different\n",
    "df_all_routes.shape, df_routes_after_join.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you want to keep your data from at least one of your tables, you should use a left join instead of an inner join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `LEFT JOIN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> A **left join** will join two tables together and but will keep all data from the first (left) table using the key provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](./images/left_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example of a left and right join:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    table1.column_name,\n",
    "    table2.different_column_name\n",
    "FROM\n",
    "    table1\n",
    "    LEFT JOIN table2\n",
    "        ON table1.shared_column_name = table2.shared_column_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code Example for Left Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recall our example using an inner join and how it lost some data since the key wasn't in both the `routes` _and_ `airlines` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_all_routes = pd.read_sql('''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        routes\n",
    "''', conn)\n",
    "\n",
    "# This will lose some data (some routes not included)\n",
    "df_routes_after_inner_join = pd.read_sql('''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        routes\n",
    "        INNER JOIN airlines\n",
    "            ON routes.airline_id = airlines.id\n",
    "''', conn)\n",
    "\n",
    "# The number of rows are different\n",
    "df_all_routes.shape, df_routes_after_inner_join.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If wanted to ensure we always had every route even if the key in `airlines` was not found, we could replace our `INNER JOIN` with a `LEFT JOIN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT *\n\nFROM\n    routes as RT\n    LEFT JOIN airlines as al\n        ON routes.airline_id = al.id\n': no such column: routes.airline_id",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such column: routes.airline_id",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This will include all the data from routes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_routes_after_inner_join \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43mSELECT *\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43mFROM\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m    routes as RT\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m    LEFT JOIN airlines as al\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m        ON routes.airline_id = al.id\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    563\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2070\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2077\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2080\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2081\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT *\n\nFROM\n    routes as RT\n    LEFT JOIN airlines as al\n        ON routes.airline_id = al.id\n': no such column: routes.airline_id"
     ]
    }
   ],
   "source": [
    "# This will include all the data from routes\n",
    "df_routes_after_inner_join = pd.read_sql('''\n",
    "SELECT *\n",
    "\n",
    "FROM\n",
    "    routes as RT\n",
    "    LEFT JOIN airlines as al\n",
    "        ON routes.airline_id = al.id\n",
    "WHERE\n",
    "''', conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise: Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which airline has the most routes listed in our database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_routes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  num_routes\n",
       "0  Ryanair        2484"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "pd.read_sql('''\n",
    "SELECT \n",
    "    al.name,\n",
    "    COUNT(*) AS num_routes\n",
    "FROM\n",
    "    routes AS rt\n",
    "    INNER JOIN airlines AS al\n",
    "        ON rt.airline_id = al.id\n",
    "GROUP BY\n",
    "    al.name\n",
    "ORDER BY \n",
    "    num_routes DESC\n",
    "LIMIT 1\n",
    "'''\n",
    ", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "pd.read_sql('''\n",
    "SELECT \n",
    "    al.name as airlineName,\n",
    "    rt.equipment as routeplane,\n",
    "    ap.code as airportcode\n",
    "FROM\n",
    "    routes AS rt\n",
    "    INNER JOIN airlines AS al\n",
    "        ON rt.airline_id = al.id\n",
    "    INNER JOIN airports as ap\n",
    "        ON rt.source_id = ap.id\n",
    "'''\n",
    ", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Execution Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```SQL\n",
    "SELECT \n",
    "    COUNT(table2.col2) AS my_new_count\n",
    "    ,table1.col2\n",
    "FROM\n",
    "    table1\n",
    "    JOIN table2\n",
    "        ON table1.col1 = table2.col2\n",
    "WHERE\n",
    "    table1.col1 > 0\n",
    "GROUP BY\n",
    "    table2.col1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. `From`\n",
    "2. `Where`\n",
    "3. `Group By`\n",
    "4. `Having`\n",
    "5. `Select`\n",
    "6. `Order By`\n",
    "7. `Limit`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
