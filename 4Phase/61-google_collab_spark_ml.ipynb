{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "hG25inuOFAzW"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Set-Up-Spark-Context\" data-toc-modified-id=\"Set-Up-Spark-Context-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set Up Spark Context</a></span></li><li><span><a href=\"#Loading-and-Preprocessing-the-Example-Data\" data-toc-modified-id=\"Loading-and-Preprocessing-the-Example-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading and Preprocessing the Example Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Process-the-Features\" data-toc-modified-id=\"Process-the-Features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Process the Features</a></span></li></ul></li><li><span><a href=\"#Train-and-Predict-with-Random-Forest\" data-toc-modified-id=\"Train-and-Predict-with-Random-Forest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train and Predict with Random Forest</a></span></li><li><span><a href=\"#Evaluate-the-Model\" data-toc-modified-id=\"Evaluate-the-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluate the Model</a></span></li><li><span><a href=\"#Using-Pipeline-and-Performing-a-Grid-Search-for-Optimal-Parameters\" data-toc-modified-id=\"Using-Pipeline-and-Performing-a-Grid-Search-for-Optimal-Parameters-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Using Pipeline and Performing a Grid Search for Optimal Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-with-Cross-Validation-to-Find-Optimal-Model\" data-toc-modified-id=\"Evaluate-with-Cross-Validation-to-Find-Optimal-Model-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Evaluate with Cross Validation to Find Optimal Model</a></span></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fvds8CiFAzZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flatiron-school/DS-Live-022122/blob/main/Phase4/62-spark-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5c378d7f-7259-4e33-bbaf-7627af7cbb7a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzaiJ8TMFAzZ",
        "outputId": "e7740ea7-861e-4ceb-add8-a20c5f32432b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.2.1\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=97e7fa5d131f4f5797f3ae29cfbc3df8469884742bdf34c7e822a02e21311450\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 36.6 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.28.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.7.3)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.6)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz<2023 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2022.2.1)\n",
            "Requirement already satisfied: packaging<22 in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.12.0)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.40)\n",
            "Collecting docker<6,>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: pandas<2 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.5.0)\n",
            "Collecting prometheus-flask-exporter<1\n",
            "  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic<2->mlflow) (5.9.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask<3->mlflow) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython<4,>=2.1.0->mlflow) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn<21->mlflow) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask<3->mlflow) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22->mlflow) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2->mlflow) (2.8.2)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.3)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=3eb0a28e7e7e4145a96879c17dc8833510291d20d1f6b935a7c7eb96e96dc2c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/73/87/c1e4b2145eb6049bb6c9aaf7ea1e38302b77ca219b6fef5d5c\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: smmap, websocket-client, pyjwt, prometheus-client, Mako, gitdb, querystring-parser, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
            "Successfully installed Mako-1.2.2 alembic-1.8.1 databricks-cli-0.17.3 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 mlflow-1.28.0 prometheus-client-0.14.1 prometheus-flask-exporter-0.20.3 pyjwt-2.4.0 querystring-parser-1.2.4 smmap-5.0.0 websocket-client-1.4.1\n"
          ]
        }
      ],
      "source": [
        "# Run for Google Colab environment\n",
        "!pip install pyspark==3.2.1\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670",
          "showTitle": false,
          "title": ""
        },
        "id": "TdSyN3VhFAza"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpOec2B5FAza",
        "outputId": "a98210d0-61cb-405e-e48d-ae62d357a376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-06 18:37:00--  https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220906T183505Z&X-Amz-Expires=300&X-Amz-Signature=3d471ea26b5fed249bddcfe4f88c736e776cf43dfa2b9e208568d6aba3295630&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-06 18:37:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220906%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220906T183505Z&X-Amz-Expires=300&X-Amz-Signature=3d471ea26b5fed249bddcfe4f88c736e776cf43dfa2b9e208568d6aba3295630&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96748 (94K) [application/octet-stream]\n",
            "Saving to: ‘US_births_2000-2014_SSA.csv’\n",
            "\n",
            "US_births_2000-2014 100%[===================>]  94.48K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-09-06 18:37:01 (5.27 MB/s) - ‘US_births_2000-2014_SSA.csv’ saved [96748/96748]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get data directly from repo\n",
        "!wget https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF2lpF8RFAzb"
      },
      "source": [
        "# Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TioYnAbgFAzb"
      },
      "source": [
        "- Use `pyspark` to build machine learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLfKCxKCFAzb"
      },
      "source": [
        "# Set Up Spark Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670",
          "showTitle": false,
          "title": ""
        },
        "id": "ok8Psr1VFAzc"
      },
      "outputs": [],
      "source": [
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6pBvfeyFAzc"
      },
      "source": [
        "# Loading and Preprocessing the Example Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "af6b675c-1cb3-4b11-9882-1d7ba0b48d47",
          "showTitle": false,
          "title": ""
        },
        "id": "Tkwhl3DZFAzc"
      },
      "source": [
        "This example assumes that we have a holdout validation dataset somewhere else, so we don't need to perform a train-test split, we only need to perform cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a7ff68e5-303d-4c4d-92c2-7a011fb94797",
          "showTitle": false,
          "title": ""
        },
        "scrolled": true,
        "id": "2biFlWFAFAzd"
      },
      "outputs": [],
      "source": [
        "# Load the file since we downloaded it earlie\n",
        "df = spark.read.format('csv').option('header', 'true').\\\n",
        "load('US_births_2000-2014_SSA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f6263aeb-3b11-42af-a198-a568bcee1aeb",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "W-waQVmCFAzd",
        "outputId": "48de992e-c501-4a9c-af6d-966bdc7faa5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year month date_of_month day_of_week births\n",
              "0  2000     1             1           6   9083\n",
              "1  2000     1             2           7   8006\n",
              "2  2000     1             3           1  11363"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fbb6451-0bca-4045-a0f3-15273b245462\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date_of_month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>births</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>9083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>8006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>11363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fbb6451-0bca-4045-a0f3-15273b245462')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fbb6451-0bca-4045-a0f3-15273b245462 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fbb6451-0bca-4045-a0f3-15273b245462');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.toPandas().head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yh5M6NyFAzd"
      },
      "source": [
        "## Process the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d39ba897-3457-4e14-b998-f25b26c409da",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZzIuMosFAzd",
        "outputId": "49719692-dc00-4165-9daf-6f15bd35f379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('year', 'string'),\n",
              " ('month', 'string'),\n",
              " ('date_of_month', 'string'),\n",
              " ('day_of_week', 'string'),\n",
              " ('births', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Types\n",
        "df = df.withColumn('births', df['births'].cast('int'))\n",
        "df = df.withColumn('day_of_week', df['day_of_week'].cast('int'))\n",
        "df = df.withColumn('date_of_month', df['date_of_month'].cast('int'))\n",
        "df = df.withColumn('month', df['month'].cast('int'))\n",
        "df = df.withColumn('year', df['year'].cast('int'))"
      ],
      "metadata": {
        "id": "BicZNGnCGapp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8w0pDSLGgvj",
        "outputId": "e540edfe-3859-46c3-b3a6-34b3465f57af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('year', 'int'),\n",
              " ('month', 'int'),\n",
              " ('date_of_month', 'int'),\n",
              " ('day_of_week', 'int'),\n",
              " ('births', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "86a93804-96e8-4885-bb5b-c54e419a0916",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyQwZbV-FAzd",
        "outputId": "9d563a32-9103-45fe-b0bd-bf48366e6d4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(year=2000, month=1, date_of_month=1, day_of_week=6, births=9083, date_vec=SparseVector(31, {1: 1.0}), day_vec=SparseVector(7, {6: 1.0}))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# OHE!\n",
        "ohe = feature.OneHotEncoder(inputCols=['date_of_month',\n",
        "                                       'day_of_week'],\n",
        "                            outputCols=['date_vec',\n",
        "                                        'day_vec'],\n",
        "                            dropLast=True)\n",
        "one_hot_encoded = ohe.fit(df).transform(df)\n",
        "one_hot_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "62567225-2c4a-4ff3-8b70-a20c0a2b46af",
          "showTitle": false,
          "title": ""
        },
        "id": "02p8ktf8FAze"
      },
      "source": [
        "Note the 'SparseVector' we've created!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7565c684-3a6c-4e7f-9ac1-0c8544ce6fae",
          "showTitle": false,
          "title": ""
        },
        "id": "w_Pubft-FAze"
      },
      "source": [
        "The Vector Assembler is often what we want when we're building a model in Spark. [How does the VectorAssembler work?](https://spark.apache.org/docs/2.1.0/ml-features.html#vectorassembler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fUjoyRTSFAze"
      },
      "outputs": [],
      "source": [
        "# Create the vector\n",
        "features = ['year', 'month', 'date_of_month', 'day_of_week']\n",
        "\n",
        "target = 'births'\n",
        "\n",
        "vector = VectorAssembler(inputCols=features, outputCol='features')\n",
        "vectorized_df = vector.transform(one_hot_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwTqTviAIGjh",
        "outputId": "4ee5ffb8-bc9d-49a5-a749-4f74d67484af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------------+-----------+------+---------------+-------------+--------------------+\n",
            "|year|month|date_of_month|day_of_week|births|       date_vec|      day_vec|            features|\n",
            "+----+-----+-------------+-----------+------+---------------+-------------+--------------------+\n",
            "|2000|    1|            1|          6|  9083| (31,[1],[1.0])|(7,[6],[1.0])|[2000.0,1.0,1.0,6.0]|\n",
            "|2000|    1|            2|          7|  8006| (31,[2],[1.0])|    (7,[],[])|[2000.0,1.0,2.0,7.0]|\n",
            "|2000|    1|            3|          1| 11363| (31,[3],[1.0])|(7,[1],[1.0])|[2000.0,1.0,3.0,1.0]|\n",
            "|2000|    1|            4|          2| 13032| (31,[4],[1.0])|(7,[2],[1.0])|[2000.0,1.0,4.0,2.0]|\n",
            "|2000|    1|            5|          3| 12558| (31,[5],[1.0])|(7,[3],[1.0])|[2000.0,1.0,5.0,3.0]|\n",
            "|2000|    1|            6|          4| 12466| (31,[6],[1.0])|(7,[4],[1.0])|[2000.0,1.0,6.0,4.0]|\n",
            "|2000|    1|            7|          5| 12516| (31,[7],[1.0])|(7,[5],[1.0])|[2000.0,1.0,7.0,5.0]|\n",
            "|2000|    1|            8|          6|  8934| (31,[8],[1.0])|(7,[6],[1.0])|[2000.0,1.0,8.0,6.0]|\n",
            "|2000|    1|            9|          7|  7949| (31,[9],[1.0])|    (7,[],[])|[2000.0,1.0,9.0,7.0]|\n",
            "|2000|    1|           10|          1| 11668|(31,[10],[1.0])|(7,[1],[1.0])|[2000.0,1.0,10.0,...|\n",
            "|2000|    1|           11|          2| 12611|(31,[11],[1.0])|(7,[2],[1.0])|[2000.0,1.0,11.0,...|\n",
            "|2000|    1|           12|          3| 12398|(31,[12],[1.0])|(7,[3],[1.0])|[2000.0,1.0,12.0,...|\n",
            "|2000|    1|           13|          4| 11815|(31,[13],[1.0])|(7,[4],[1.0])|[2000.0,1.0,13.0,...|\n",
            "|2000|    1|           14|          5| 12180|(31,[14],[1.0])|(7,[5],[1.0])|[2000.0,1.0,14.0,...|\n",
            "|2000|    1|           15|          6|  8525|(31,[15],[1.0])|(7,[6],[1.0])|[2000.0,1.0,15.0,...|\n",
            "|2000|    1|           16|          7|  7657|(31,[16],[1.0])|    (7,[],[])|[2000.0,1.0,16.0,...|\n",
            "|2000|    1|           17|          1| 10824|(31,[17],[1.0])|(7,[1],[1.0])|[2000.0,1.0,17.0,...|\n",
            "|2000|    1|           18|          2| 12350|(31,[18],[1.0])|(7,[2],[1.0])|[2000.0,1.0,18.0,...|\n",
            "|2000|    1|           19|          3| 12405|(31,[19],[1.0])|(7,[3],[1.0])|[2000.0,1.0,19.0,...|\n",
            "|2000|    1|           20|          4| 12506|(31,[20],[1.0])|(7,[4],[1.0])|[2000.0,1.0,20.0,...|\n",
            "+----+-----+-------------+-----------+------+---------------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPYMZ0AAFAze"
      },
      "source": [
        "# Train and Predict with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5a4278a2-0a2b-4fb2-9fcc-86545c194c1a",
          "showTitle": false,
          "title": ""
        },
        "id": "GZSfK1JPFAze"
      },
      "outputs": [],
      "source": [
        "# Instantiante\n",
        "rf_model = RandomForestRegressor(featuresCol='features',\n",
        "                                 labelCol='births',\n",
        "                                 predictionCol=\"prediction\").fit(vectorized_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e2a65c25-7be6-43b3-ad0a-a0efec038fac",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHw24n1zFAze",
        "outputId": "3fecff00-148d-4969-c04d-3a32e32d3147"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(births=9083, prediction=8570.769112316098),\n",
              " Row(births=8006, prediction=7989.466058016709),\n",
              " Row(births=11363, prediction=11567.76319651733)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Predictions\n",
        "predictions = rf_model.transform(vectorized_df).select(\"births\", \"prediction\")\n",
        "predictions.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-y2ge_NFAzf"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "8f61139f-c7eb-4319-9dea-d62cfce1cb6d",
          "showTitle": false,
          "title": ""
        },
        "id": "jbKQm8lSFAzf"
      },
      "source": [
        "Let's evaluate our model! [Here](https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html) is a reference for the many metrics available in Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "30d59b5c-5586-4984-a964-4ff9945aeaf8",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaEZV2JgFAzf",
        "outputId": "fc3a7bc3-6d62-4210-e995-0786fa16535c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8954124057635579"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Create it\n",
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births')\n",
        "\n",
        "evaluator.evaluate(predictions, {evaluator.metricName:\"r2\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "eb8adf31-10e4-4b94-90bc-b1d9a77407c8",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctXmuT-ZFAzf",
        "outputId": "ab6b14ca-4a8a-40ab-b34f-92c3e101cc45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "413.4328364865637"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Evaluate it!\n",
        "evaluator.evaluate(predictions, {evaluator.metricName:\"mae\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(predictions, {evaluator.metricName:\"rmse\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nwwKbZvIzNi",
        "outputId": "a080001d-80b3-4d84-bf5e-0f32c011d68d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "752.102006126674"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6sf1wLmFAzf"
      },
      "source": [
        "# Using Pipeline and Performing a Grid Search for Optimal Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "71e41dd8-9242-45ee-924c-8a34a8efb364",
          "showTitle": false,
          "title": ""
        },
        "id": "B3YD7ByeFAzf"
      },
      "outputs": [],
      "source": [
        "# Instantiante and create steps\n",
        "one_hot_encoder = OneHotEncoder(inputCols=['date_of_month',\n",
        "                                                'day_of_week'],\n",
        "                                     outputCols=['date_vec',\n",
        "                                                  'day_vec'],\n",
        "                                     dropLast=True)\n",
        "\n",
        "vector_assember = VectorAssembler(inputCols=features,\n",
        "                                  outputCol='features')\n",
        "\n",
        "random_forest = RandomForestRegressor(featuresCol='features',\n",
        "                                      labelCol='births')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aer5O10OFAzf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "71e41dd8-9242-45ee-924c-8a34a8efb364",
          "showTitle": false,
          "title": ""
        },
        "id": "lstBHu0LFAzf"
      },
      "outputs": [],
      "source": [
        "# Create Pipeline stages\n",
        "stages = [one_hot_encoder, vector_assember, random_forest]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "71e41dd8-9242-45ee-924c-8a34a8efb364",
          "showTitle": false,
          "title": ""
        },
        "id": "C0EZT_QLFAzf"
      },
      "outputs": [],
      "source": [
        "#Instantiate pipeline\n",
        "pipeline = Pipeline(stages=stages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7f22a487-ae2a-4c7e-85bc-a15edfdc601d",
          "showTitle": false,
          "title": ""
        },
        "id": "6keL7JTeFAzg"
      },
      "source": [
        "Note: The stages in a pipeline can be either *Transformers* or *Estimators*. An estimator fits a DataFrame to produce a Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d3d1c4a4-9534-4292-b0c2-e894568b18fd",
          "showTitle": false,
          "title": ""
        },
        "id": "6DHTrqcpFAzg"
      },
      "outputs": [],
      "source": [
        "# Get possible params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "37cb006e-18b0-482a-86e5-e791db4af5ba",
          "showTitle": false,
          "title": ""
        },
        "id": "gy-izXfeFAzg"
      },
      "outputs": [],
      "source": [
        "# Build parameter grid\n",
        "params = ParamGridBuilder().addGrid(random_forest.numTrees, [20, 50, 100]).build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e5a25b89-173d-4125-aee4-8a669ea2e865",
          "showTitle": false,
          "title": ""
        },
        "id": "ZDz1zAfHFAzg"
      },
      "outputs": [],
      "source": [
        "# Build Evaluator\n",
        "reg_evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births',\n",
        "                                    metricName='rmse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUGLXPGFAzg"
      },
      "source": [
        "## Evaluate with Cross Validation to Find Optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "679011e7-8b9b-4f45-a39a-2b82f8424d6b",
          "showTitle": false,
          "title": ""
        },
        "id": "-NX-qB_LFAzg"
      },
      "outputs": [],
      "source": [
        "# Cross Validatate!\n",
        "cv = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=params,\n",
        "    evaluator=reg_evaluator,\n",
        "    parallelism=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validated_model = cv.fit(df.cache())"
      ],
      "metadata": {
        "id": "CpWEt0MmMeGO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validated_model.avgMetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilgdlL2tMnoP",
        "outputId": "c78e70e7-001f-4a27-e80b-8cdada3b4401"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[765.4188840029694, 776.2722291452679, 769.2397563829315]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validated_model.bestModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A02YS1q1NejA",
        "outputId": "5af5b59c-01b8-400e-f273-578d7b404f11"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineModel_61e1f35e2f79"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validated_model.bestModel.stages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UjU5KajNg4g",
        "outputId": "8ff8b8dd-f361-413f-bde8-cf40e90b9bfd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OneHotEncoderModel: uid=OneHotEncoder_0f96327b6365, dropLast=true, handleInvalid=error, numInputCols=2, numOutputCols=2,\n",
              " VectorAssembler_4d513ea89f96,\n",
              " RandomForestRegressionModel: uid=RandomForestRegressor_8feb99c0f5bf, numTrees=20, numFeatures=4]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validated_model.bestModel.stages[2].getNumTrees"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIXhu6CiNpNj",
        "outputId": "563acf0b-1779-43d7-a346-d6860c2408de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9e_d4hoNN3e3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookName": "03-spark-ml",
      "notebookOrigID": 835564910129657,
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "TOC",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "288px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}